{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.dataset import SegmentationDataset, TransformDataset, transforms as T\n",
    "from utils.vis import show_torch_batch, show_torch_img\n",
    "from utils.metrics import ConfusionMatrix\n",
    "from models import deeplabv3, half_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "disable_cuda = False\n",
    "num_classes = 2\n",
    "num_epochs = 30\n",
    "batch_size = 4\n",
    "ignore_index = 100  # Value of labels that we ignore in loss and other logic (e.g. kelp with unknown species)\n",
    "prep_datasets = False\n",
    "dataset_path = Path('../checkpoints/datasets.pt')\n",
    "\n",
    "if not disable_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results reproducable\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_opts = {\n",
    "    \"batch_size\": batch_size, \n",
    "    \"pin_memory\": True, \n",
    "    \"drop_last\": True,\n",
    "    \"num_workers\": os.cpu_count()\n",
    "}\n",
    "\n",
    "if prep_datasets:\n",
    "    ds_paths = [\n",
    "        \"../data/datasets/Calvert_2012\",\n",
    "        \"../data/datasets/Calvert_2015\", \n",
    "        \"../data/datasets/Calvert_ChokedNorthBeach_2016\", \n",
    "        \"../data/datasets/Calvert_WestBeach_2016\"\n",
    "    ]\n",
    "    ds = torch.utils.data.ConcatDataset([SegmentationDataset(path) for path in ds_paths])\n",
    "\n",
    "    train_num = int(len(ds) * 0.8)\n",
    "    val_num = len(ds) - train_num\n",
    "    ds_train, ds_val = torch.utils.data.random_split(ds, [train_num, val_num])\n",
    "\n",
    "    # Bind data transforms to the subset datasets\n",
    "    ds_train = TransformDataset(ds_train, T.train_transforms, T.train_target_transforms)\n",
    "    ds_val = TransformDataset(ds_val, T.test_transforms, T.test_target_transforms)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(ds_train, shuffle=True, **dataloader_opts),\n",
    "        'eval': DataLoader(ds_val, shuffle=False, **dataloader_opts),\n",
    "    }\n",
    "\n",
    "    print(\"Training samples:\", train_num)\n",
    "    print(\"Validation samples:\", val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_pixel_stats(dataloader):\n",
    "    pixel_counts = torch.zeros((num_classes)).to(device)\n",
    "\n",
    "    for _, y in tqdm(iter(dataloader)):\n",
    "        try:\n",
    "            un, counts = torch.unique(y.to(device), return_counts=True)\n",
    "            mask = un != ignore_index\n",
    "            pixel_counts.index_add_(0, un[mask], counts[mask].float())\n",
    "        except Exception:\n",
    "            import pdb; pdb.set_trace()\n",
    "    \n",
    "    pixel_ratio = pixel_counts / pixel_counts.sum(dim=0)\n",
    "    pixel_counts = pixel_counts.detach().cpu().numpy()\n",
    "    pixel_ratio = np.around(pixel_ratio.detach().cpu().numpy(), 4)\n",
    "    \n",
    "    return pixel_ratio, pixel_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prep_datasets:\n",
    "    train_proportions, train_counts = ds_pixel_stats(dataloaders['train'])\n",
    "    print(train_proportions)\n",
    "    plt.figure(); plt.bar(range(num_classes), train_proportions); plt.show()\n",
    "\n",
    "    val_proportions, val_counts = ds_pixel_stats(dataloaders['eval'])\n",
    "    print(val_proportions) \n",
    "    plt.figure(); plt.bar(range(num_classes), val_proportions); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample kelp-free empty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_of_kelp_images(dataset):\n",
    "    dl = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "    indices = []\n",
    "    \n",
    "    for i, (_, y) in enumerate(tqdm(iter(dl))):\n",
    "        if torch.any(y > 0):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "if prep_datasets:\n",
    "    train_indices = get_indices_of_kelp_images(ds_train)\n",
    "    val_indices = get_indices_of_kelp_images(ds_val)\n",
    "\n",
    "    ds_train = torch.utils.data.Subset(ds_train, train_indices)\n",
    "    ds_val = torch.utils.data.Subset(ds_val, val_indices)\n",
    "    ds_overfit = torch.utils.data.Subset(ds_train, range(0, batch_size))\n",
    "\n",
    "    torch.save({\n",
    "        'train': ds_train,\n",
    "        'val': ds_val,\n",
    "        'overfit': ds_overfit\n",
    "    }, dataset_path)\n",
    "else:\n",
    "    dataset_saved = torch.load(dataset_path)\n",
    "    ds_train = dataset_saved['train']\n",
    "    ds_val = dataset_saved['val']\n",
    "    ds_overfit = dataset_saved['overfit']\n",
    "    \n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(ds_train, shuffle=True, **dataloader_opts),\n",
    "    'eval': DataLoader(ds_val, shuffle=False, **dataloader_opts),\n",
    "    'overfit': DataLoader(ds_overfit, shuffle=False, **dataloader_opts)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b675840c94715acc7a7bc27029dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=573.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.6924 0.3076]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c687332b71a9448fb3cb48616f2c9dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.6709 0.3291]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_proportions, train_counts = ds_pixel_stats(dataloaders['train'])\n",
    "print(train_proportions)\n",
    "plt.figure(); plt.bar(range(num_classes), train_proportions); plt.show()\n",
    "\n",
    "val_proportions, val_counts = ds_pixel_stats(dataloaders['eval'])\n",
    "print(val_proportions) \n",
    "plt.figure(); plt.bar(range(num_classes), val_proportions); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net, opt, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss import CBLoss\n",
    "\n",
    "model = deeplabv3.create_model(num_classes)\n",
    "model = model.to(device)\n",
    "# model = half_precision(model)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "criterion = CBLoss(train_counts.astype(np.int32), num_classes, \"focal\", 0.9999, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit to a single batch to ensure things work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def overfit_model_to_single_batch(model, dataloader, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    info = OrderedDict()\n",
    "    sum_iou = np.zeros(num_classes)\n",
    "    cm = ConfusionMatrix(num_classes).to(device)\n",
    "    \n",
    "    with trange(1, num_epochs+1) as pbar:\n",
    "        for epoch in pbar:\n",
    "            for x, y in dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pred = model(x)['out']\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if epoch % 100 == 0:\n",
    "                    show_torch_batch(x, y, pred)\n",
    "\n",
    "                # Compute metrics\n",
    "                loss = loss.detach().cpu().item()\n",
    "                info['batch_loss'] = loss\n",
    "\n",
    "                cm.update(y, pred.max(dim=1)[1])\n",
    "                info['IoUs'] = np.around(np.nan_to_num(cm.get_iou().detach().cpu().numpy()), 4)\n",
    "\n",
    "                pbar.set_postfix(info)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# model = overfit_model_to_single_batch(model, dataloaders['overfit'], optimizer, criterion, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, num_classes, optimizer, criterion, num_epochs, save_path, start_epoch=0):\n",
    "    info = OrderedDict()\n",
    "    \n",
    "    best_loss = None\n",
    "    \n",
    "    for epoch in trange(start_epoch, num_epochs, desc=\"epoch\"):\n",
    "        sum_loss = 0.\n",
    "        sum_iou = np.zeros(num_classes)\n",
    "        cm = ConfusionMatrix(num_classes).to(device)\n",
    "        \n",
    "        for phase in ['train', 'eval']:\n",
    "            with tqdm(iter(dataloaders[phase]), desc=phase) as pbar:\n",
    "                for i, (x, y) in enumerate(pbar):\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        model.train()\n",
    "                    else:\n",
    "                        model.eval()\n",
    "\n",
    "                    pred = model(x)['out']\n",
    "                    loss = criterion(pred, y)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Compute metrics\n",
    "                    sum_loss += loss.detach().cpu().item()\n",
    "                    info['mean_loss'] = sum_loss / (i+1)\n",
    "\n",
    "                    mask = y != ignore_index\n",
    "                    cm.update(y[mask], pred.max(dim=1)[1][mask])\n",
    "                    info['IoUs'] = np.around(np.nan_to_num(cm.get_iou().detach().cpu().numpy()), 4)\n",
    "\n",
    "                    pbar.set_postfix(info)\n",
    "            \n",
    "            # Show a batch of images\n",
    "            show_torch_batch(x, y, pred)\n",
    "                \n",
    "        # Model checkpointing after eval stage\n",
    "        if best_loss is None or info['mean_loss'] < best_loss:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'mean_eval_loss': info['mean_loss'],\n",
    "                }, save_path)\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d9e4b905d747e2982feca49b10fc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=30.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a024ff3d5774d7b811da199dd50e669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=573.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/tadenoud/PycharmProjects/uav-classif/utils/loss.py(83)__call__()\n",
      "-> labels_one_hot = F.one_hot(labels, self.no_of_classes).float()\n",
      "(Pdb) labels.shape\n",
      "torch.Size([4, 200, 200])\n",
      "(Pdb) n\n",
      "> /home/tadenoud/PycharmProjects/uav-classif/utils/loss.py(85)__call__()\n",
      "-> weights = self.weights.repeat(labels_one_hot.shape[0], 1) * labels_one_hot\n",
      "(Pdb) labels_one_hot.shape\n",
      "torch.Size([4, 200, 200, 2])\n",
      "(Pdb) labels_one_hot\n",
      "tensor([[[[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          ...,\n",
      "          [1., 0.],\n",
      "          [1., 0.],\n",
      "          [1., 0.]]]], device='cuda:0')\n",
      "(Pdb) ll\n",
      " 76  \t    def __call__(self, logits, labels):\n",
      " 77  \t        \"\"\"\n",
      " 78  \t        Args:\n",
      " 79  \t          labels: A int tensor of size [batch].\n",
      " 80  \t          logits: A float tensor of size [batch, no_of_classes].\n",
      " 81  \t        \"\"\"\n",
      " 82  \t        import pdb; pdb.set_trace()\n",
      " 83  \t        labels_one_hot = F.one_hot(labels, self.no_of_classes).float()\n",
      " 84  \t\n",
      " 85  ->\t        weights = self.weights.repeat(labels_one_hot.shape[0], 1) * labels_one_hot\n",
      " 86  \t        weights = weights.sum(1)\n",
      " 87  \t        weights = weights.unsqueeze(1)\n",
      " 88  \t        weights = weights.repeat(1, self.no_of_classes)\n",
      " 89  \t\n",
      " 90  \t        if self.loss_type == \"focal\":\n",
      " 91  \t            return focal_loss(labels_one_hot, logits, weights, self.gamma)\n",
      " 92  \t        elif self.loss_type == \"sigmoid\":\n",
      " 93  \t            return F.binary_cross_entropy_with_logits(input=logits, target=labels_one_hot, weights=weights)\n",
      " 94  \t        elif self.loss_type == \"softmax\":\n",
      " 95  \t            pred = logits.softmax(dim=1)\n",
      " 96  \t            return F.binary_cross_entropy(input=pred, target=labels_one_hot, weight=weights)\n",
      "(Pdb) q\n",
      "\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-03314e720929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-009517af8eb6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, num_classes, optimizer, criterion, num_epochs, save_path, start_epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/uav-classif/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, logits, labels)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mlabels_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/uav-classif/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, logits, labels)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mlabels_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uav/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uav/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "save_path = Path('../checkpoints/deeplabv3/checkpoint2.pt')\n",
    "save_path.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if Path(save_path).exists():\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "else:\n",
    "    epoch = 0\n",
    "\n",
    "model =  train_model(model, dataloaders, num_classes, optimizer, criterion, num_epochs, save_path, start_epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Change mixed class to don't care\n",
    "- Try different optimizer\n",
    "- ~~Train for Kelp/Not Kelp only~~\n",
    "- Check that changing prior doesn't affect performance too badly\n",
    "- Optimize regularization\n",
    "\n",
    "## TO TRY\n",
    "- Add Jaccard index loss as in https://www.kaggle.com/windsurfer/baseline-u-net-on-pytorch\n",
    "- Straight Jaccard loss\n",
    "- ~~Undersample Kelp-free images~~\n",
    "- Oversample images with kelp\n",
    "- Try UNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
