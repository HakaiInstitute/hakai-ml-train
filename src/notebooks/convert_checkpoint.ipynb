{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from models.lit_lraspp_mobilenet_v3_large import LRASPPMobileNetV3Large\n",
    "from models.lit_unet import UnetEfficientnet\n",
    "def train():\n",
    "    pass\n",
    "\n",
    "DEVICE = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "weights_path = \"/home/taylor/PycharmProjects/hakai-ml-train/checkpoints/mussels/UNET/Aug2022/val_miou=0.8196_epoch=62.ckpt\"\n",
    "torchscript_path = \"/home/taylor/PycharmProjects/hakai-ml-train/checkpoints/mussels/UNET/Aug2022/UNet_mussel_presence_jit.pt\"\n",
    "model = UnetEfficientnet.load_from_checkpoint(weights_path, train=False, map_location=DEVICE, strict=False, num_classes=2)\n",
    "# model.to_torchscript(file_path=torchscript_path, method='trace', example_inputs=x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Save state_dict only\n",
    "# torch.save(model.state_dict(), Path(weights_path).with_suffix(\".pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nPython builtin <built-in method apply of FunctionMeta object at 0x5600a72d4700> is currently not supported in Torchscript:\n  File \"/home/taylor/mambaforge/envs/ml-train/lib/python3.10/site-packages/efficientnet_pytorch/utils.py\", line 80\n    def forward(self, x):\n        return SwishImplementation.apply(x)\n               ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 6\u001B[0m     traced_model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_torchscript\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     traced_model\u001B[38;5;241m.\u001B[39msave(torchscript_path)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1916\u001B[0m, in \u001B[0;36mLightningModule.to_torchscript\u001B[0;34m(self, file_path, method, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1913\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_running_torchscript \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscript\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1916\u001B[0m     torchscript_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscript\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrace\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# if no example inputs are provided, try to see if model has example_input_array set\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m example_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_script.py:1286\u001B[0m, in \u001B[0;36mscript\u001B[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001B[0m\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[1;32m   1285\u001B[0m     obj \u001B[38;5;241m=\u001B[39m call_prepare_scriptable_func(obj)\n\u001B[0;32m-> 1286\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_recursive\u001B[38;5;241m.\u001B[39mcreate_script_module(\n\u001B[1;32m   1287\u001B[0m         obj, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_recursive\u001B[38;5;241m.\u001B[39minfer_methods_to_compile\n\u001B[1;32m   1288\u001B[0m     )\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m create_script_dict(obj)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:458\u001B[0m, in \u001B[0;36mcreate_script_module\u001B[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tracing:\n\u001B[1;32m    457\u001B[0m     AttributeTypeIsSupportedChecker()\u001B[38;5;241m.\u001B[39mcheck(nn_module)\n\u001B[0;32m--> 458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:520\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    517\u001B[0m     script_module\u001B[38;5;241m.\u001B[39m_concrete_type \u001B[38;5;241m=\u001B[39m concrete_type\n\u001B[1;32m    519\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 520\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m concrete_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m concrete_type_store\u001B[38;5;241m.\u001B[39mmethods_compiled:\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001B[39;00m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n\u001B[1;32m    619\u001B[0m RecursiveScriptModule\u001B[38;5;241m.\u001B[39m_finalize_scriptmodule(script_module)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:498\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    495\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m orig_value\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 498\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n\u001B[1;32m    501\u001B[0m script_module\u001B[38;5;241m.\u001B[39m_modules[name] \u001B[38;5;241m=\u001B[39m scripted\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:520\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    517\u001B[0m     script_module\u001B[38;5;241m.\u001B[39m_concrete_type \u001B[38;5;241m=\u001B[39m concrete_type\n\u001B[1;32m    519\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 520\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m concrete_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m concrete_type_store\u001B[38;5;241m.\u001B[39mmethods_compiled:\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001B[39;00m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n\u001B[1;32m    619\u001B[0m RecursiveScriptModule\u001B[38;5;241m.\u001B[39m_finalize_scriptmodule(script_module)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:498\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    495\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m orig_value\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 498\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n\u001B[1;32m    501\u001B[0m script_module\u001B[38;5;241m.\u001B[39m_modules[name] \u001B[38;5;241m=\u001B[39m scripted\n",
      "    \u001B[0;31m[... skipping similar frames: RecursiveScriptModule._construct at line 615 (2 times), create_script_module_impl at line 520 (2 times), create_script_module_impl.<locals>.init_fn at line 498 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:520\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    517\u001B[0m     script_module\u001B[38;5;241m.\u001B[39m_concrete_type \u001B[38;5;241m=\u001B[39m concrete_type\n\u001B[1;32m    519\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 520\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m concrete_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m concrete_type_store\u001B[38;5;241m.\u001B[39mmethods_compiled:\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001B[39;00m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n\u001B[1;32m    619\u001B[0m RecursiveScriptModule\u001B[38;5;241m.\u001B[39m_finalize_scriptmodule(script_module)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:498\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    495\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m orig_value\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 498\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n\u001B[1;32m    501\u001B[0m script_module\u001B[38;5;241m.\u001B[39m_modules[name] \u001B[38;5;241m=\u001B[39m scripted\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:524\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m concrete_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m concrete_type_store\u001B[38;5;241m.\u001B[39mmethods_compiled:\n\u001B[0;32m--> 524\u001B[0m     \u001B[43mcreate_methods_and_properties_from_stubs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconcrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_stubs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproperty_stubs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001B[39;00m\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001B[39;00m\n\u001B[1;32m    527\u001B[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001B[0;32m~/mambaforge/envs/ml-train/lib/python3.10/site-packages/torch/jit/_recursive.py:375\u001B[0m, in \u001B[0;36mcreate_methods_and_properties_from_stubs\u001B[0;34m(concrete_type, method_stubs, property_stubs)\u001B[0m\n\u001B[1;32m    372\u001B[0m property_defs \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mdef_ \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m property_stubs]\n\u001B[1;32m    373\u001B[0m property_rcbs \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mresolution_callback \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m property_stubs]\n\u001B[0;32m--> 375\u001B[0m \u001B[43mconcrete_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_methods_and_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproperty_defs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproperty_rcbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_defs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_rcbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_defaults\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \nPython builtin <built-in method apply of FunctionMeta object at 0x5600a72d4700> is currently not supported in Torchscript:\n  File \"/home/taylor/mambaforge/envs/ml-train/lib/python3.10/site-packages/efficientnet_pytorch/utils.py\", line 80\n    def forward(self, x):\n        return SwishImplementation.apply(x)\n               ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.rand(1, 3, 8, 8, device=DEVICE, requires_grad=False)\n",
    "\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "with torch.no_grad():\n",
    "    traced_model = model.to_torchscript(example_inputs=x)\n",
    "    traced_model.save(torchscript_path)\n",
    "# torch.onnx.export(model, x, \"torchscript_files/LRASPP_MobileNetV3_kelp_species.onnx\",\n",
    "#                   opset_version=11, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}