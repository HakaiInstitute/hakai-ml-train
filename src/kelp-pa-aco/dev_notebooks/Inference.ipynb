{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e07dee1-a55f-4be5-a372-3f262fc6eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import auto, Enum\n",
    "import os\n",
    "import tempfile\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import rasterio\n",
    "from rasterio.windows import Window, union\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from hanning import get_bartlett_hann_kernel, Kernel, BartlettHannKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd62794c-d3e5-467e-8554-a992644365f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SIZE = 1024\n",
    "NUM_CLASSES = 2\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "# IMG_PATH = \"/mnt/aco-uvic/Taylor_temp/23_3031_01_NW_Calvert_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_subset3.tif\"\n",
    "# OUTPUT_PATH = \"/mnt/aco-uvic/Taylor_temp/23_3031_01_NW_Calvert_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_subset3_kelp_pa.tif\"\n",
    "\n",
    "# IMG_PATH = \"/mnt/aco-uvic/Taylor_temp/23_3033_01_Triquet_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_subset.tif\"\n",
    "# OUTPUT_PATH = \"/mnt/aco-uvic/Taylor_temp/23_3033_01_Triquet_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_subset_kelp_pa.tif\"\n",
    "\n",
    "# IMG_PATH = \"/mnt/aco-uvic/2023_Acquisitions/02_Processed/23_3033_01_Triquet_CCKelp/02_ORTHO/01_Products/23_3033_01_Triquet_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_FINAL.tif\"\n",
    "# OUTPUT_PATH = \"/mnt/data/Taylor/23_3033_01_Triquet_CCKelp_ORTHO_CSRS_UTM9_CGG2013a_kelp_pa.tif\"\n",
    "\n",
    "IMG_PATH = \"/mnt/aco-uvic/2023_Acquisitions/02_Processed/23_3058_01_SalishSea/02_ORTHO/01_Products/23_3058_01_SalishSea_ORTHO_CSRS_UTM10_CGG2013a_with_sfm_DEM_cog.tif\"\n",
    "OUTPUT_PATH = \"/mnt/data/Taylor/23_3058_01_SalishSea_ORTHO_CSRS_UTM10_CGG2013a_with_sfm_DEM_kelp_pa.tif\"\n",
    "\n",
    "MODEL_WEIGHTS = \"./UNET_Resnet34_kelp_presence_aco_jit_miou=0.8323.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46765d62-f982-4971-b7f2-97b4bd127045",
   "metadata": {},
   "source": [
    "# Classification v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8d6ff24-7b5d-4fa7-b6d1-1601855304b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(MODEL_WEIGHTS, \"rb\") as f: \n",
    "#     model = torch.jit.load(f, map_location=DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d55803-4839-4b1a-a42d-3cae57ccab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each set of 4x4 image windows (less/more?), forward prop through net to get prediction. Stride is half of window size (e.g. 2x2)\n",
    "# def generate_windows(tile_size, img_height, img_width):\n",
    "#     stride = tile_size // 2\n",
    "    \n",
    "#     for row_start in range(0, img_height, stride):\n",
    "#         for col_start in range(0, img_width, stride):\n",
    "#             row_stop = min(row_start + tile_size, img_height)\n",
    "#             col_stop = min(col_start + tile_size, img_width)\n",
    "#             yield Window.from_slices((row_start, row_stop), (col_start, col_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7c3e3b8-97f7-453c-9a93-94de8123fdc2",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmppm7gmsgl.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01beae54ccc4e189d34a1319ed278d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from rasterio.io import MemoryFile\n",
    "\n",
    "# ZEROS_CHIP = np.zeros((NUM_CLASSES, CLIP_SIZE//2, CLIP_SIZE//2), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# # with MemoryFile() as output_temp:\n",
    "# with tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as output_temp_f:\n",
    "#     output_temp = output_temp_f.name\n",
    "#     print(output_temp)\n",
    "    \n",
    "#     # Write a new single band geotiff with the same size and CRS as the src image and all pixels==0\n",
    "#     with rasterio.open(IMG_PATH) as src:\n",
    "#         # Initialize temp register file\n",
    "#         profile = src.profile\n",
    "#         profile.update({ \"count\": NUM_CLASSES, \"height\": int(CLIP_SIZE*1.5), \"dtype\": \"float32\", \"bigtiff\": \"IF_SAFER\" })\n",
    "#         with rasterio.open(output_temp, \"w\", **profile) as dest:\n",
    "#             pass\n",
    "\n",
    "#         # Initialize final output file\n",
    "#         profile = src.profile\n",
    "#         profile.update({ \"count\": 1, \"dtype\": \"uint8\", \"bigtiff\": \"IF_SAFER\" })\n",
    "#         with rasterio.open(OUTPUT_PATH, 'w', **profile) as dest:\n",
    "#             pass\n",
    "\n",
    "    \n",
    "#     with rasterio.open(IMG_PATH) as src:\n",
    "#         windows = list(generate_windows(CLIP_SIZE, src.profile['height'], src.profile['width']))\n",
    "#         last_col_off = windows[-1].col_off\n",
    "#         last_row_off = windows[-1].row_off\n",
    "        \n",
    "#         for window in tqdm(windows):\n",
    "#             x = torch.tensor(src.read(window=window), device=DEVICE, dtype=torch.uint8)\n",
    "            \n",
    "#             # zero pad to size\n",
    "#             _, th, tw = x.shape\n",
    "#             dh = CLIP_SIZE - th\n",
    "#             dw = CLIP_SIZE - tw\n",
    "#             x = torch.nn.functional.pad(x, (0,dw,0,dh), mode='constant', value=0)\n",
    "            \n",
    "#             if (x == 0).all():    \n",
    "#                 # Mock softmax outputs for BG with 100% confidence\n",
    "#                 pred = torch.zeros((NUM_CLASSES, CLIP_SIZE, CLIP_SIZE), device=DEVICE)\n",
    "#                 pred[0] = 1\n",
    "#             else:\n",
    "#                 # Preprocessing\n",
    "#                 # to float\n",
    "#                 x = x.to(torch.float) / 255\n",
    "#                 # min-max scale\n",
    "#                 min_, _ = torch.kthvalue(x.flatten().unique(), 2)\n",
    "#                 max_ = x.flatten().max()\n",
    "#                 x = torch.clamp((x - min_) / (max_ - min_ + 1e-8), 0, 1)\n",
    "    \n",
    "#                 # batch_size=1\n",
    "#                 x = x.unsqueeze(dim=0)\n",
    "                \n",
    "#                 # Prediction\n",
    "#                 with torch.no_grad():\n",
    "#                     pred = model.forward(x).squeeze(dim=0)\n",
    "            \n",
    "#             # Convolve with hann window\n",
    "#             kernel = get_bartlett_hann_kernel(\n",
    "#                 size=CLIP_SIZE,\n",
    "#                 device=DEVICE,\n",
    "#                 is_top=(window.row_off == 0),\n",
    "#                 is_bottom=(window.row_off == last_row_off),\n",
    "#                 is_left=(window.col_off == 0),\n",
    "#                 is_right=(window.col_off == last_col_off),\n",
    "#             )\n",
    "#             kernel_pred = torch.mul(kernel, pred)\n",
    "                \n",
    "#             # Strip padding\n",
    "#             kernel_pred = kernel_pred[:, :th, :tw]\n",
    "            \n",
    "#             # Read any existing data writen to the output and add to the new data\n",
    "#             with rasterio.open(output_temp, 'r+') as register, rasterio.open(OUTPUT_PATH, 'r+', **profile) as dest:\n",
    "#                 # 1. Read and write to the registry\n",
    "#                 # | | | |\n",
    "#                 # |x|x| |\n",
    "#                 # |x|x| |\n",
    "#                 win = Window(col_off=window.col_off, row_off=CLIP_SIZE//2, height=window.height, width=window.width)\n",
    "#                 with torch.no_grad():\n",
    "#                     existing_values = torch.tensor(register.read(window=win), device=DEVICE)\n",
    "#                     logits_xxxx = existing_values + kernel_pred\n",
    "#                 # Write the new data to the output\n",
    "#                 register.write(logits_xxxx.detach().cpu().numpy(), window=win)\n",
    "\n",
    "#                 # 2. Write the values that are information complete (The upper left of the above window)\n",
    "#                 # | | | |\n",
    "#                 # |x| | |\n",
    "#                 # | | | |\n",
    "#                 logits_x = logits_xxxx[:,:min(CLIP_SIZE//2, window.height),:min(CLIP_SIZE//2, window.width)]\n",
    "#                 win = Window(col_off=window.col_off, row_off=window.row_off, height=min(CLIP_SIZE//2, window.height), width=min(CLIP_SIZE//2, window.width))\n",
    "#                 dest.write(logits_x.argmax(axis=0).detach().cpu().numpy(), indexes=1, window=win)\n",
    "\n",
    "#                 # 3. Update registry\n",
    "#                 # | | | |      |x| | |\n",
    "#                 # |x|o| |  ->  |x|o| |\n",
    "#                 # |x|o| |      | |o| |\n",
    "#                 logits_xx = logits_xxxx[:,:,:min(CLIP_SIZE//2, window.width)]\n",
    "#                 write_win = Window(col_off=window.col_off, row_off=0, height=window.height, width=min(CLIP_SIZE//2, window.width))\n",
    "#                 zero_win = Window(col_off=window.col_off, row_off=CLIP_SIZE, height=CLIP_SIZE//2, width=min(CLIP_SIZE//2, window.width))\n",
    "#                 register.write(logits_xx.detach().cpu().numpy(), window=write_win)\n",
    "#                 register.write(ZEROS_CHIP, window=zero_win)\n",
    "                \n",
    "#                 # If last col, do the same as above for the right half of the window\n",
    "#                 # I think this never happens..? The last tile will always be < CLIP_SIZE//2 wide. Except maybe if it is exactly CLIP_SIZE//2?\n",
    "#                 if window.col_off == last_col_off and window.width > CLIP_SIZE//2:\n",
    "#                     import pdb; pdb.set_trace()\n",
    "#                     # 2. Write the values that are information complete (The upper left of the above window)\n",
    "#                     # | | | |\n",
    "#                     # | | |x|\n",
    "#                     # | | |o|  # This section saved for later, to prevent extra read\n",
    "#                     logits_x = logits_xxxx[:,:min(CLIP_SIZE//2, window.height),min(CLIP_SIZE//2, window.width):]\n",
    "#                     win = Window(col_off=(window.col_off+CLIP_SIZE//2), row_off=window.row_off, height=min(CLIP_SIZE//2, window.height), width=(window.width-CLIP_SIZE//2))\n",
    "#                     dest.write(logits_x.argmax(axis=0).detach().cpu().numpy(), indexes=1, window=win)\n",
    "\n",
    "#                     # 3. Update registry\n",
    "#                     # | |o| |      | |o|x|\n",
    "#                     # | |o|x|  ->  | |o|x|\n",
    "#                     # | | |x|      | | | |\n",
    "#                     logits_xx = logits_xxxx[:,:,min(CLIP_SIZE//2, window.width):]\n",
    "#                     write_win = Window(col_off=(window.col_off+CLIP_SIZE//2), row_off=0, height=window.height, width=(window.width-CLIP_SIZE//2))\n",
    "#                     zero_win = Window(col_off=(window.col_off+CLIP_SIZE//2), row_off=CLIP_SIZE, height=CLIP_SIZE//2, width=(window.width-CLIP_SIZE//2))\n",
    "#                     register.write(logits_xx.detach().cpu().numpy(), window=write_win)\n",
    "#                     register.write(ZEROS_CHIP, window=zero_win)\n",
    "\n",
    "#             # Postprocess logits\n",
    "#             # with :\n",
    "#             #     windows = list(src.block_windows(1))\n",
    "#             #     for ji, window in tqdm(windows):\n",
    "#             #         logits = np.stack([src.read(k+1, window=window) for k in range(NUM_CLASSES)], axis=0)\n",
    "#             #         preds = logits.argmax(axis=0)\n",
    "#             #         dest.write(preds, indexes=1, window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43ece3-5c03-43ea-bf40-5c2439aecbba",
   "metadata": {},
   "source": [
    "# Classification v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3e39f5-52a6-4bf6-b00a-efd787db816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryRegister(object):\n",
    "    def __init__(self, image_path: str, num_classes: int, window_size: int, device: torch.device.type):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.n = num_classes\n",
    "        self.ws = window_size\n",
    "        self.hws = window_size//2\n",
    "        self.device = device\n",
    "\n",
    "        # Copy metadata from img\n",
    "        with rasterio.open(image_path, 'r') as src:\n",
    "            self.width = math.ceil(src.width / self.ws) * self.ws\n",
    "        self.height = self.ws\n",
    "        self.register = np.zeros((self.n, self.height, self.width+self.hws))\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        del self.register\n",
    "    \n",
    "    @property\n",
    "    def _zero_chip(self):\n",
    "        return torch.zeros((self.n, self.hws, self.hws), dtype=torch.float, device=self.device)\n",
    "        \n",
    "    def step(self, new_logits: torch.Tensor, img_window: Window):\n",
    "        # 1. Read data from the registry to update with the new logits\n",
    "        # |a|b| |\n",
    "        # |c|d| |\n",
    "        with torch.no_grad():\n",
    "            logits_abcd = torch.tensor(self.register[:,:,img_window.col_off:img_window.col_off+self.ws], device=self.device)\n",
    "            logits_abcd += new_logits\n",
    "\n",
    "        # Move data around and write to the registry to make new space for the next row of processing windows      \n",
    "        # |c|b| | + pop a\n",
    "        # |0|d| |\n",
    "        logits_a = logits_abcd[:,:self.hws,:self.hws]\n",
    "        logits_c = logits_abcd[:,self.hws:,:self.hws]\n",
    "        logits_c0 = torch.concat([logits_c, self._zero_chip], dim=1).detach().cpu().numpy()\n",
    "        logits_bd = logits_abcd[:,:,self.hws:].detach().cpu().numpy()\n",
    "\n",
    "        # write c0\n",
    "        self.register[:,:,img_window.col_off:img_window.col_off+self.hws] = logits_c0\n",
    "\n",
    "        # write bd\n",
    "        col_off_bd = img_window.col_off+self.hws\n",
    "        win_bd = Window(col_off=col_off_bd, row_off=0, height=self.ws, width=self.hws)\n",
    "        self.register[:,:,col_off_bd:col_off_bd+self.hws] = logits_bd\n",
    "        \n",
    "        # Return the information complete predictions (argmax of a, stripped over overflowing padding)\n",
    "        preds_win = Window(col_off=img_window.col_off, row_off=img_window.row_off, \n",
    "                           height=min(self.hws, img_window.height), width=min(self.hws, img_window.width))\n",
    "        preds = logits_a[:, :img_window.height, :img_window.width].argmax(axis=0)\n",
    "\n",
    "        return preds, preds_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5602c6-6d04-4e1e-8854-4d79aaf86ecd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RasterRegister(object):\n",
    "    def __init__(self, image_path: str, num_classes: int, window_size: int, device: torch.device.type):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.tf = tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False)\n",
    "        self.n = num_classes\n",
    "        self.ws = window_size\n",
    "        self.hws = window_size//2\n",
    "        self.device = device\n",
    "\n",
    "        # Copy metadata from img\n",
    "        with rasterio.open(self.image_path) as src:\n",
    "            working_profile = src.profile\n",
    "            self.height = self.ws\n",
    "            self.width = math.ceil(src.width / self.ws) * self.ws\n",
    "            working_profile.update({\n",
    "                \"count\": self.n, \"height\": self.height, \"width\": self.width, \n",
    "                \"dtype\": \"float32\", \"bigtiff\": \"IF_SAFER\" \n",
    "            })\n",
    "            \n",
    "            # Initialize empty registry file\n",
    "            with rasterio.open(self.tf.name, \"w\", **working_profile) as dest:\n",
    "                pass\n",
    "\n",
    "        # Open registry file in append mode \n",
    "        self.register = rasterio.open(self.tf.name, \"r+\")\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.register.close()\n",
    "        self.tf.close()\n",
    "        os.unlink(self.tf.name)\n",
    "    \n",
    "    @property\n",
    "    def _zero_chip(self):\n",
    "        return torch.zeros((self.n, self.hws, self.hws), dtype=torch.float, device=self.device)\n",
    "        \n",
    "    def step(self, new_logits: torch.Tensor, img_window: Window):\n",
    "        # 1. Read data from the registry to update with the new logits\n",
    "        # |a|b| |\n",
    "        # |c|d| |\n",
    "        win = Window(col_off=img_window.col_off, row_off=0, height=self.ws, width=self.ws)\n",
    "        with torch.no_grad():\n",
    "            logits_abcd = torch.tensor(self.register.read(window=win, boundless=True, fill_value=0), device=self.device)\n",
    "            logits_abcd += new_logits\n",
    "\n",
    "        # Move data around and write to the registry to make new space for the next row of processing windows      \n",
    "        # |c|b| | + pop a\n",
    "        # |0|d| |\n",
    "        logits_a = logits_abcd[:,:self.hws,:self.hws]\n",
    "        logits_c = logits_abcd[:,self.hws:,:self.hws]\n",
    "        logits_c0 = torch.concat([logits_c, self._zero_chip], dim=1).detach().cpu().numpy()\n",
    "        logits_bd = logits_abcd[:,:,self.hws:].detach().cpu().numpy()\n",
    "\n",
    "        win_c0 = Window(col_off=img_window.col_off, row_off=0, height=self.ws, width=self.hws)\n",
    "        self.register.write(logits_c0, window=win_c0)\n",
    "\n",
    "        col_off_bd = img_window.col_off+self.hws\n",
    "        if col_off_bd + self.hws <= self.width:\n",
    "            win_bd = Window(col_off=col_off_bd, row_off=0, height=self.ws, width=self.hws)\n",
    "            self.register.write(logits_bd, window=win_bd)\n",
    "        \n",
    "        # Return the information complete predictions (argmax of a, stripped over overflowing padding)\n",
    "        preds_win = Window(col_off=img_window.col_off, row_off=img_window.row_off, \n",
    "                           height=min(self.hws, img_window.height), width=min(self.hws, img_window.width))\n",
    "        preds = logits_a[:, :img_window.height, :img_window.width].argmax(axis=0)\n",
    "\n",
    "        return preds, preds_win\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8f5131-ee39-41fa-aa76-261a31053d9a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141c8ef6fc28465cac46993f5e6ab9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HannWindowSegmentation(object):\n",
    "    def __init__(self, model: torch.nn.Module, kernel: Kernel,\n",
    "                 num_classes: int, window_size: int, device: torch.device.type):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.kernel = kernel(window_size, device)\n",
    "        self.n = num_classes\n",
    "        self.ws = window_size\n",
    "        self.hws = window_size//2\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def _pure_black_pred(self):\n",
    "        \"\"\"Shortcut prediction for any tiles that are all black. Equal to a pred of BG for all pixels\"\"\"\n",
    "        pred = torch.zeros((self.n, self.ws, self.ws), device=self.device)\n",
    "        pred[0] = 1\n",
    "        return pred\n",
    "\n",
    "    def _window_generator(self, img_height: int, img_width: int):\n",
    "        for row_start in range(0, img_height, self.hws):\n",
    "            for col_start in range(0, img_width, self.hws):\n",
    "                row_stop = min(row_start + self.ws, img_height)\n",
    "                col_stop = min(col_start + self.ws, img_width)\n",
    "                yield Window.from_slices((row_start, row_stop), (col_start, col_stop))\n",
    "\n",
    "    def _pad_tile(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # zero pad image data to consistent window size\n",
    "        _, th, tw = x.shape\n",
    "        return torch.nn.functional.pad(x, (0, self.ws - tw, 0, self.ws - th), mode='constant', value=0)\n",
    "\n",
    "    def _preprocess(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # to float\n",
    "        x = x.to(torch.float) / 255\n",
    "        # min-max scale\n",
    "        min_, _ = torch.kthvalue(x.flatten().unique(), 2)\n",
    "        max_ = x.flatten().max()\n",
    "        x = torch.clamp((x - min_) / (max_ - min_ + 1e-8), 0, 1)\n",
    "\n",
    "        # batch_size=1\n",
    "        x = x.unsqueeze(dim=0)\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, img_path: str, output_path: str):\n",
    "        # Initialize the output file and working file\n",
    "        self._init_output_file(img_path, output_path)\n",
    "\n",
    "        # Classification\n",
    "        with rasterio.open(img_path) as src, MemoryRegister(img_path, self.n, self.ws, self.device) as register, rasterio.open(output_path, 'r+') as dest:\n",
    "            windows = list(self._window_generator(src.height, src.width))\n",
    "            last_col_off = windows[-1].col_off\n",
    "            last_row_off = windows[-1].row_off\n",
    "            \n",
    "            for window in tqdm(windows):\n",
    "                x = torch.tensor(src.read(window=window), device=self.device, dtype=torch.uint8)\n",
    "                x = self._pad_tile(x)\n",
    "                \n",
    "                if (x == 0).all():    \n",
    "                    # Mock softmax outputs for BG with 100% confidence\n",
    "                    pred = self._pure_black_pred\n",
    "                else:\n",
    "                    # Prediction\n",
    "                    x = self._preprocess(x)\n",
    "                    with torch.no_grad():\n",
    "                        pred = model.forward(x).squeeze(dim=0)\n",
    "                \n",
    "                # Multiply by hann window\n",
    "                with torch.no_grad():\n",
    "                    kernel_pred = self.kernel(\n",
    "                        pred, \n",
    "                        top=(window.row_off == 0), \n",
    "                        bottom=(window.row_off == last_row_off),\n",
    "                        left=(window.col_off == 0),\n",
    "                        right=(window.col_off == last_col_off)\n",
    "                    )\n",
    "                \n",
    "                # Update the registry with intermediate data and recieve complete predictions\n",
    "                preds, pred_win = register.step(kernel_pred, window)\n",
    "                dest.write(preds.detach().cpu().numpy(), indexes=1, window=pred_win)\n",
    "        \n",
    "    \n",
    "    def _init_output_file(self, img_path: str, output_path: str):\n",
    "        \"\"\"Write a new single band geotiff with the same size and CRS as the src image and all pixels==0\"\"\"\n",
    "        with rasterio.open(img_path) as src:     \n",
    "            # Initialize final output file\n",
    "            output_profile = src.profile\n",
    "            output_profile.update({ \"count\": 1, \"dtype\": \"uint8\", \"bigtiff\": \"IF_SAFER\" })\n",
    "            with rasterio.open(output_path, 'w', **output_profile) as dest:\n",
    "                pass\n",
    "                \n",
    "    @classmethod\n",
    "    def run(cls, img_path: str, output_path: str, model: torch.nn.Module, kernel: Kernel, num_classes: int, window_size: int, device: torch.device.type):\n",
    "        self = cls(model, kernel, num_classes, window_size, device)\n",
    "        return self(img_path, output_path)\n",
    "\n",
    "with open(MODEL_WEIGHTS, \"rb\") as f: \n",
    "    model = torch.jit.load(f, map_location=DEVICE).eval()\n",
    "    \n",
    "HannWindowSegmentation.run(IMG_PATH, OUTPUT_PATH, model, BartlettHannKernel, NUM_CLASSES, CLIP_SIZE, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693a265e-2e60-493a-b904-b8c642fe5723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Inference.ipynb to script\n",
      "[NbConvertApp] Writing 19588 bytes to Inference.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1abd4ac-71cc-4969-8b0d-d12369b33aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gradio interface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
