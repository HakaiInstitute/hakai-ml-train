{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio.shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models.UNet import UNet\n",
    "from utils.dataset.SegmentationDataset import SegmentationDataset\n",
    "from utils.dataset.transforms import transforms as T\n",
    "from utils.eval import predict_tiff, eval_model\n",
    "from utils.loss import assymetric_tversky_loss\n",
    "from utils.loss import iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DISABLE_CUDA = False\n",
    "\n",
    "# For running script locally without Docker use these for e.g\n",
    "checkpoint_dir = Path('unet/seagrass/checkpoints')\n",
    "weights_dir = Path('unet/seagrass/model_weights')\n",
    "train_data_dir = Path('unet/seagrass/train_input/data/train')\n",
    "eval_data_dir = Path('unet/seagrass/train_input/data/eval')\n",
    "seg_in_dir = Path(\"unet/seagrass/train_input/data/segmentation\")\n",
    "seg_out_dir = Path(\"unet/seagrass/train_output/segmentation\")\n",
    "restart_training = False\n",
    "\n",
    "# Load hyper-parameters dictionary\n",
    "num_classes = 2  # \"2\",\n",
    "num_epochs = 200  # \"200\",\n",
    "batch_size = 1  # \"8\",\n",
    "lr = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Make results reproducible\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)\n",
    "\n",
    "if not DISABLE_CUDA and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check ratio of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SegmentationDataset(train_data_dir, transform=T.test_transforms,\n",
    "                               target_transform=T.test_target_transforms)\n",
    "ds_val = SegmentationDataset(eval_data_dir, transform=T.test_transforms,\n",
    "                             target_transform=T.test_target_transforms)\n",
    "\n",
    "dataloader_opts = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"pin_memory\": True,\n",
    "    \"drop_last\": True,\n",
    "    \"num_workers\": os.cpu_count()\n",
    "}\n",
    "data_loaders = {\n",
    "    'train': DataLoader(ds_train, shuffle=False, **dataloader_opts),\n",
    "    'eval': DataLoader(ds_val, shuffle=False, **dataloader_opts),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totals = {\n",
    "#     'train': np.zeros((2,)),\n",
    "#     'eval': np.zeros((2,))\n",
    "# }\n",
    "\n",
    "# for phase in ['train', 'eval']:\n",
    "#     for _, y in tqdm(data_loaders[phase]):\n",
    "#         y = y.to(device)\n",
    "#         values, counts = torch.unique(y, return_counts=True)\n",
    "\n",
    "#         for i, c in zip(values, counts):\n",
    "#             totals[phase][i] += c\n",
    "\n",
    "#     print(totals[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.bar([\"not seagrass\", \"seagrass\"], totals['train'])\n",
    "# plt.title(\"Train\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.bar([\"not seagrass\", \"seagrass\"], totals['eval'])\n",
    "# plt.title(\"Eval\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vegetation indices for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 513, 513])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def add_veg_indices(x):\n",
    "    \"\"\"Add a slew of RGB vegetation indices to the image.\n",
    "    x: torch.Tensor RGB image of shape (n, c, h, w)\n",
    "\n",
    "    returns modified image tensor with bands in order\n",
    "        n, [rgbvi, vari, gli, ngrdi, r, g, b], h, w\n",
    "    \"\"\"\n",
    "    x = add_ngrdi_band(x)\n",
    "    x = add_gli_band(x)\n",
    "    x = add_vari_band(x)\n",
    "    x = add_rgbvi_band(x)\n",
    "    return x\n",
    "    \n",
    "def add_rgbvi_band(img):\n",
    "    \"\"\"Add RGBVI as band 0.\n",
    "    img: a Torch tensor of shape (n, c, h, w)\n",
    "     It is assumed there are at least 3 channels, \n",
    "        with RGB located at index -3, -2, -1, respectively\n",
    "\n",
    "    returns img of shape (n, c+1, h, w)\n",
    "    \"\"\"\n",
    "    r, g, b = img[:,-3,:,:], img[:,-2,:,:], img[:,-1,:,:]\n",
    "\n",
    "    rgbvi = (torch.mul(r,r) - torch.mul(r,b)) / (torch.mul(g,g) + torch.mul(r,b))\n",
    "    return torch.cat((rgbvi.unsqueeze(1), img), dim=1)\n",
    "\n",
    "def add_gli_band(img):\n",
    "    \"\"\"Add GLI as band 0.\n",
    "    img: a Torch tensor of shape (n, c, h, w)\n",
    "\n",
    "    returns img of shape (n, c+1, h, w)\n",
    "    \"\"\"\n",
    "    r, g, b = img[:,-3,:,:], img[:,-2,:,:], img[:,-1,:,:]\n",
    "    gli = (2*g - r - b) / (2*g + r + b)\n",
    "    return torch.cat((gli.unsqueeze(1), img), dim=1)\n",
    "\n",
    "def add_vari_band(img):\n",
    "    \"\"\"Add VARI as band 0.\n",
    "    img: a Torch tensor of shape (n, c, h, w)\n",
    "\n",
    "    returns img of shape (n, c+1, h, w)\n",
    "    \"\"\"\n",
    "    r, g, b = img[:,-3,:,:], img[:,-2,:,:], img[:,-1,:,:]\n",
    "    vari = (g - r) / (g + r - b)\n",
    "    return torch.cat((vari.unsqueeze(1), img), dim=1)\n",
    "\n",
    "def add_ngrdi_band(img):\n",
    "    \"\"\"Add NGRDI as band 0.\n",
    "    img: a Torch tensor of shape (n, c, h, w)\n",
    "\n",
    "    returns img of shape (n, c+1, h, w)\n",
    "    \"\"\"\n",
    "    r, g, b = img[:,-3,:,:], img[:,-2,:,:], img[:,-1,:,:]\n",
    "    ngrdi = (g - r) / (g + r)\n",
    "    return torch.cat((ngrdi.unsqueeze(1), img), dim=1)\n",
    "\n",
    "out = add_veg_indices(next(iter(data_loaders['train']))[0])\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create UNet instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 7  # [rgbvi, vari, gli, ngrdi, r, g, b]\n",
    "\n",
    "# Model\n",
    "os.environ['TORCH_HOME'] = str(checkpoint_dir.parents[0])\n",
    "model = UNet(n_channels=n_channels, n_classes=num_classes, bilinear=True)\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assymetric_tversky_loss(p, g, beta=1.):\n",
    "    \"\"\"Loss function from the paper S. R. Hashemi, et al, 2018. \"Asymmetric loss functions and deep densely-connected\n",
    "    networks for highly-imbalanced medical image segmentation: application to multiple sclerosis lesion detection\"\n",
    "    https://ieeexplore.ieee.org/abstract/document/8573779.\n",
    "    Electronic ISSN: 2169-3536. DOI: 10.1109/ACCESS.2018.2886371.\n",
    "\n",
    "    p: predicted output from a sigmoid-like activation. (i.e. range is 0-1)\n",
    "    g: ground truth label of pixel (0 or 1)\n",
    "    beta: parameter that adjusts weight between FP and FN error importance. beta=1. simplifies to the Dice loss function\n",
    "    (F1 score) and weights both FP and FNs equally. B=0 is precicion, B=2 is the F_2 score\n",
    "\n",
    "    >>> np.around(assymetric_tversky_loss(torch.Tensor([0.9, 0.5, 0.2]), torch.Tensor([1., 0., 1.]), beta=1.).numpy(), 6)\n",
    "    0.611111\n",
    "    \"\"\"\n",
    "    p = p.flatten().float()\n",
    "    g = g.flatten().float()\n",
    "    bsq = beta * beta\n",
    "    pg = torch.sum(torch.mul(p, g))\n",
    "    similarity_coeff = ((1 + bsq) * pg) / (\n",
    "        ((1 + bsq) * pg) + (bsq * torch.sum(torch.mul((1 - p), g))) + (torch.sum(torch.mul(p, (1 - g))))\n",
    "    )\n",
    "    \n",
    "    return 1 - similarity_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./unet/unet.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "def alpha_blend(bg, fg, alpha=0.5):\n",
    "    return fg * alpha + bg * (1 - alpha)\n",
    "\n",
    "\n",
    "def train_model(model, device, dataloaders, num_classes, optimizer, criterion, num_epochs, checkpoint_dir, output_dir,\n",
    "                lr_scheduler=None, start_epoch=0):\n",
    "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    log_dir = os.path.join(checkpoint_dir.joinpath('runs', current_time + '_' + socket.gethostname()))\n",
    "\n",
    "    writers = {\n",
    "        'train': SummaryWriter(log_dir=log_dir + '_train'),\n",
    "        'eval': SummaryWriter(log_dir=log_dir + '_eval')\n",
    "    }\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_val_iou_seagrass = None\n",
    "    best_val_miou = None\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        for phase in ['train']:\n",
    "            sum_loss = 0.\n",
    "            sum_iou = np.zeros(num_classes)\n",
    "\n",
    "            for x, y in tqdm(iter(dataloaders[phase]), desc=f\"{phase} epoch {epoch}\", file=sys.stdout):\n",
    "                y = y.to(device)\n",
    "                x = x.to(device)\n",
    "                \n",
    "                # Add vegetation indices\n",
    "                x = add_veg_indices(x)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                pred = model(x)\n",
    "#                 loss = criterion(pred.float(), y)\n",
    "                sig = torch.sigmoid(pred[:,1])\n",
    "                loss = assymetric_tversky_loss(sig, y, beta=1.)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Compute metrics\n",
    "                sum_loss += loss.detach().cpu().item()\n",
    "                sum_iou += iou(y, pred.float()).detach().cpu().numpy()\n",
    "\n",
    "            mloss = sum_loss / len(dataloaders[phase])\n",
    "            ious = np.around(sum_iou / len(dataloaders[phase]), 4)\n",
    "            miou = np.mean(ious)\n",
    "            iou_bg = sum_iou[0] / len(dataloaders[phase])\n",
    "            iou_seagrass = sum_iou[1] / len(dataloaders[phase])\n",
    "\n",
    "            print(f'{phase}-loss={mloss}; {phase}-miou={miou}; {phase}-iou-bg={iou_bg}; {phase}-iou-seagrass={iou_seagrass};')\n",
    "\n",
    "            writers[phase].add_scalar('Loss', mloss, epoch)\n",
    "            writers[phase].add_scalar('IoU/Mean', miou, epoch)\n",
    "            writers[phase].add_scalar('IoU/BG', iou_bg, epoch)\n",
    "            writers[phase].add_scalar('IoU/Kelp', iou_seagrass, epoch)\n",
    "\n",
    "            # Show images\n",
    "            x = x[:,-3:,:,:]\n",
    "            img_grid = torchvision.utils.make_grid(x, nrow=8)\n",
    "            img_grid = T.inv_normalize(img_grid)\n",
    "\n",
    "            y = y.unsqueeze(dim=1)\n",
    "            label_grid = torchvision.utils.make_grid(y, nrow=8).cuda()\n",
    "            label_grid = alpha_blend(img_grid, label_grid)\n",
    "            writers[phase].add_image('Labels/True', label_grid.detach().cpu(), epoch)\n",
    "\n",
    "            pred = pred.max(dim=1)[1].unsqueeze(dim=1)\n",
    "            pred_grid = torchvision.utils.make_grid(pred, nrow=8).cuda()\n",
    "            pred_grid = alpha_blend(img_grid, pred_grid)\n",
    "            writers[phase].add_image('Labels/Pred', pred_grid.detach().cpu(), epoch)\n",
    "\n",
    "            # Save model checkpoints\n",
    "            if phase == 'train':\n",
    "                # Model checkpoint after every train phase every epoch\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'mean_eval_loss': mloss,\n",
    "                }, Path(checkpoint_dir).joinpath('unet.pt'))\n",
    "            else:\n",
    "                # Save best models for eval set\n",
    "                if best_val_loss is None or mloss < best_val_loss:\n",
    "                    best_val_loss = mloss\n",
    "                    torch.save(model.state_dict(), Path(output_dir).joinpath('unet_best_val_loss.pt'))\n",
    "                if best_val_iou_seagrass is None or iou_seagrass < best_val_iou_seagrass:\n",
    "                    best_val_iou_seagrass = iou_seagrass\n",
    "                    torch.save(model.state_dict(), Path(output_dir).joinpath('unet_best_val_seagrass_iou.pt'))\n",
    "                if best_val_miou is None or miou < best_val_miou:\n",
    "                    best_val_miou = miou\n",
    "                    torch.save(model.state_dict(), Path(output_dir).joinpath('unet_best_val_miou.pt'))\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    writers['train'].flush()\n",
    "    writers['train'].close()\n",
    "    writers['eval'].flush()\n",
    "    writers['eval'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d630c2edd33423baad7ec9015eab4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e961f98fee34333af06da943e215114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = {'train': [], 'eval': []}\n",
    "\n",
    "for phase in ['train', 'eval']:\n",
    "    for i, (_, y) in enumerate(tqdm(data_loaders[phase])):\n",
    "        y = y.to(device)\n",
    "        values, counts = torch.unique(y, return_counts=True)\n",
    "        if len(counts) > 1:\n",
    "            indices[phase].append(i)\n",
    "            \n",
    "        if len(indices[phase]) == batch_size:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [3], 'eval': [43]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) detected\n",
      "0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e05ff8a57144dac98b50d9cfedccc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train epoch 0', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-loss=0.5541805624961853; train-miou=0.33785; train-iou-bg=0.38191282749176025; train-iou-seagrass=0.2937708795070648;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1b8e21cbfb487a8622bb52b20ac1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train epoch 1', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-loss=0.519179105758667; train-miou=0.3489; train-iou-bg=0.37440454959869385; train-iou-seagrass=0.3234141170978546;\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa57bbf133149c99ff51307e06318be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train epoch 2', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-loss=0.4683103561401367; train-miou=0.38039999999999996; train-iou-bg=0.39330166578292847; train-iou-seagrass=0.3674554228782654;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e41fe7ca2f41d2901acae81a58a071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train epoch 3', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e2d22b1f2052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m train_model(model, device, data_loaders, num_classes, optimizer, criterion, num_epochs, checkpoint_dir,\n\u001b[0;32m---> 23\u001b[0;31m             weights_dir, start_epoch=0)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c764c0966672>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, device, dataloaders, num_classes, optimizer, criterion, num_epochs, checkpoint_dir, output_dir, lr_scheduler, start_epoch)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# Compute metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0msum_iou\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(num_gpus, \"GPU(s) detected\")\n",
    "if num_gpus > 1:\n",
    "    batch_size *= num_gpus\n",
    "\n",
    "ds_train = torch.utils.data.Subset(ds_train, indices['train'])\n",
    "ds_val = torch.utils.data.Subset(ds_val, indices['eval'])\n",
    "data_loaders = {\n",
    "    'train': DataLoader(ds_train, shuffle=False, **dataloader_opts),\n",
    "    'eval': DataLoader(ds_val, shuffle=False, **dataloader_opts),\n",
    "}\n",
    "\n",
    "# Optimizer, Loss\n",
    "print(lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "checkpoint_path = checkpoint_dir.joinpath('unet.pt')\n",
    "\n",
    "train_model(model, device, data_loaders, num_classes, optimizer, criterion, num_epochs, checkpoint_dir,\n",
    "            weights_dir, start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_uav",
   "language": "python",
   "name": "python3_uav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
